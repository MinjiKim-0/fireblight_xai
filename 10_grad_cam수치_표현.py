# -*- coding: utf-8 -*-
"""10_grad cam수치 표현.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y6fJ-dWQT6coNUePWg0aWDJT3V6zBMpW

import
"""

import tensorflow as tf
import sklearn.metrics
import numpy as np
import matplotlib.pyplot as plt

"""변수설정"""

seed = 42
batch_size = 3515
img_size_299 = (299, 299)
img_size_224 = (224, 224) # resnet
tf.random.set_seed(seed)

"""모델 불러오기"""

MODEL_x = "1006-1335.hdf5" # xception
MODEL_in = "1002-1814.hdf5" # inceptionv3
MODEL_r = "0927-1902.hdf5" # resnet

x_model = tf.keras.models.load_model(f'/fire_blight/apple_model/xception/{MODEL_x}') # xception
in_model = tf.keras.models.load_model(f'/fire_blight/apple_model/InceptionV3/{MODEL_in}') # inceptionv3
r_model = tf.keras.models.load_model(f'/fire_blight/apple_model/ResNet50V2/{MODEL_r}') # resnet50v2

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255., validation_split=0.5)

test_dir = "/fire_blight/Training/apple_dataset/test" # /media/visbic/MGTEC/fireblight
# /fire_blight/Training/apple_dataset/test
# /content/drive/MyDrive/Colab Notebooks/대학원/21-2_딥러닝 응용/fireblight/apple_new -> 삭제해도 될듯

"""img_size 299 generator"""

test_generator_299 = test_datagen.flow_from_directory(test_dir,
    target_size=img_size_299,
    batch_size=batch_size,
    seed=seed,
    subset="validation") # 3282 # 3282 # 3282 # 1639

test_images_299, test_labels_299 = test_generator_299.next()

# test_loss, test_acc = loaded_model.evaluate(test_images,  test_labels, verbose=2)

# print("test_images :", test_images.shape)

"""img_size 224 generator"""

test_generator_224 = test_datagen.flow_from_directory(test_dir,
    target_size=img_size_224,
    batch_size=batch_size,
    seed=seed,
    subset="validation") # 3282 # 3282 # 3282 # 1639

test_images_224,test_labels_224 = test_generator_224.next()

# test_loss, test_acc = loaded_model.evaluate(test_images,  test_labels, verbose=2)

# print("test_images :", test_images.shape)

"""모델 예측

xception_fireblight만
"""

x_test_pred_raw=list()
for i, x in enumerate(test_labels_299[:,3]):
  if x==1:
    p = x_model.predict(test_images_299[i].reshape(1, 299, 299, 3))
    x_test_pred_raw.append(p)
x_test_pred_raw = np.array(x_test_pred_raw).reshape(355,6)
x_test_pred = np.argmax(x_test_pred_raw, axis=1)

x_rounded_labels=list()
for i, x in enumerate(test_labels_299[:,3]):
  if x==1:
    a = 1
    x_rounded_labels.append(a)
x_rounded_labels=np.array(x_rounded_labels)

print("x_rounded_labels shape :", x_rounded_labels.shape)
print("x_test_pred :", x_test_pred.shape)

"""xception_모두"""

# x_test_pred_raw=np.array(x_test_pred_raw) # (355, 1, 6)
# x_test_pred = np.argmax(x_test_pred_raw, axis=1)

# x_rounded_labels=np.argmax(test_labels_299, axis=1)

# print("x_rounded_labels shape :", x_rounded_labels.shape)
# print("x_test_pred :", x_test_pred.shape)

# # xception
# x_test_pred_raw = x_model.predict(test_images_299)
# x_test_pred = np.argmax(x_test_pred_raw, axis=1)

# x_rounded_labels=np.argmax(test_labels_299, axis=1)

# print("x_rounded_labels shape :", x_rounded_labels.shape)
# print("x_test_pred :", x_test_pred.shape)

"""inception_fireblight만"""

in_test_pred_raw=list()
for i, x in enumerate(test_labels_299[:,3]):
  if x==1:
    p = in_model.predict(test_images_299[i].reshape(1, 299, 299, 3))
    in_test_pred_raw.append(p)
in_test_pred_raw = np.array(in_test_pred_raw).reshape(355,6)
in_test_pred = np.argmax(in_test_pred_raw, axis=1)

in_rounded_labels=list()
for i, x in enumerate(test_labels_299[:,3]):
  if x==1:
    a = 1
    in_rounded_labels.append(a)
in_rounded_labels=np.array(in_rounded_labels)

print("in_rounded_labels shape :", in_rounded_labels.shape)
print("in_test_pred :", in_test_pred.shape)

"""inception_모두"""

# # inception
# in_test_pred_raw = in_model.predict(test_images_299)
# in_test_pred = np.argmax(in_test_pred_raw, axis=1)

# in_rounded_labels=np.argmax(test_labels_299, axis=1)

# print("in_rounded_labels shape :", in_rounded_labels.shape)
# print("in_test_pred :", in_test_pred.shape)

"""resnet 모두"""
# r_test_pred_raw = r_model.predict(test_images_224)
# r_test_pred = np.argmax(r_test_pred_raw, axis=1)

# r_rounded_labels=np.argmax(test_labels_224, axis=1)

# print("r_rounded_labels shape :", r_rounded_labels.shape)
# print("r_test_pred :", r_test_pred.shape)

# (x_rounded_labels == in_rounded_labels).sum()
# # xception이랑 inception은 정답 레이빌끼리 서로 다 맞음

# (x_rounded_labels == r_rounded_labels).sum()
# # resnet이랑도 다 맞음

"""resnet_fireblight만"""

r_test_pred_raw=list()
for i, x in enumerate(test_labels_299[:,3]):
  if x==1:
    p = r_model.predict(test_images_224[i].reshape(1, 224,224, 3))
    r_test_pred_raw.append(p)
r_test_pred_raw = np.array(r_test_pred_raw).reshape(355,6)
r_test_pred = np.argmax(r_test_pred_raw, axis=1)

r_rounded_labels=list()
fireblight = list()
for i, x in enumerate(test_labels_224[:,3]):
  if x==1:
    a = 1
    r_rounded_labels.append(a)
    fireblight.append(i)
r_rounded_labels=np.array(r_rounded_labels)

len(fireblight)

print("r_rounded_labels shape :", r_rounded_labels.shape)
print("r_test_pred :", r_test_pred.shape)


"""# XAI"""

from tensorflow import keras
import matplotlib.cm as cm

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # First, we create a model that maps the input image to the activations
    # of the last conv layer as well as the output predictions
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # We multiply each channel in the feature map array
    # by "how important this channel is" with regard to the top predicted class
    # then sum all the channels to obtain the heatmap class activation
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # For visualization purpose, we will also normalize the heatmap between 0 & 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

last_conv_layer_name = "block14_sepconv2_act"
x_test_pred = np.argmax(x_test_pred_raw, axis=1)
# Remove last layer's softmax
in_model.layers[-1].activation = None



img = test_images_299[354]

array = np.expand_dims(img, axis=0)

# Generate class activation heatmap|
heatmap = make_gradcam_heatmap(array, in_model, last_conv_layer_name)

# Display heatmap
plt.matshow(heatmap)
plt.show()

alpha=0.4

# Rescale heatmap to a range 0-255
heatmap = np.uint8(255 * heatmap)

# Use jet colormap to colorize heatmap
jet = cm.get_cmap("jet")

# Use RGB values of the colormap
jet_colors = jet(np.arange(256))[:, :3]
jet_heatmap = jet_colors[heatmap]

# Create an image with RGB colorized heatmap
jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)
jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)
jet_heatmap = jet_heatmap /255


# Superimpose the heatmap on original image
superimposed_img = jet_heatmap * alpha + img
superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)

# Display heatmap
plt.imshow(superimposed_img)
plt.show()

superimposed_img

# last_conv_layer_name은 model.summary()로 알아냄
def getGradcamArray(test_images_n, which_model, last_conv_layer_name):
    # Remove last layer's softmax
    which_model.layers[-1].activation = None
    ary = np.zeros(test_images_n.shape)
    for i in fireblight:
        img = test_images_n[i]

        array = np.expand_dims(img, axis=0)

        # Generate class activation heatmap|
        heatmap = make_gradcam_heatmap(array, which_model, last_conv_layer_name)

        lpha=0.4

        # Rescale heatmap to a range 0-255
        heatmap = np.uint8(255 * heatmap)

        # Use jet colormap to colorize heatmap
        jet = cm.get_cmap("jet")

        # Use RGB values of the colormap
        jet_colors = jet(np.arange(256))[:, :3]
        jet_heatmap = jet_colors[heatmap]

        # Create an image with RGB colorized heatmap
        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)
        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)
        # 이거 해야 이미지 제대로 보임
        jet_heatmap = jet_heatmap /255

        # Superimpose the heatmap on original image
        superimposed_img = jet_heatmap * alpha + img
        ary[i] = superimposed_img

    return ary

x_grad_array = getGradcamArray(test_images_299, x_model, "block14_sepconv2_act")

# "mixed10" last_conv_layer_name은 x_model.sumarry 참고해서 in_model.summary()로 알아냄
in_grad_array = getGradcamArray(test_images_299, in_model, "mixed10")

# "post_relu" last_conv_layer_name은 x_model.sumarry랑 r_model.sumarry 참고해서 r_model.summary()로 알아냄
r_grad_array = getGradcamArray(test_images_224, r_model, "post_relu")

"""# 보고싶은거2
과수화상병 50개 test 이미지에 대한 3 모델의 XAI 시각화

"""

# 과수화상병(3)에 해당하는 인덱스 50개 추리기
three = []
for i in range(x_rounded_labels.shape[0]):
    if x_rounded_labels[i] == 3:
        whatiwant = i
        three.append(whatiwant)

print(len(three))
# three

# 본래 이미지와 3개 모델의 Grad-CAM을 모두 보여주는 plot
def showPred(idx):
    # 본래 이미지
    plt.subplot(141)
    plt.imsave("1.jpg", test_images_299[idx])
    plt.title(f"original {idx}")

    # InceptionV3
    plt.subplot(142)
    plt.imsave("2.jpg", in_grad_array[idx])
    plt.title("InceptionV3")
    
    # Xception
    plt.subplot(143)
    plt.imsave("3.jpg", x_grad_array[idx])
    plt.title("Xception")

    # Resnet50V2
    plt.subplot(144)
    plt.imsave("4.jpg", r_grad_array[idx])
    plt.title("Resnet50V2")

    # plt.subplots_adjust(left=0.125, bottom=0.1, right=2, top=0.9, wspace=0.2, hspace=0.2)
    plt.subplots_adjust(wspace=0.2, hspace=0.4)
    # plt.show()

for i in three: # 50 개 반복할 수 있도록
    showPred(i)

"""# 보고싶은거 3
과수화상병 이미지 3개 시각화
"""

for i in fireblight: # 355 개 반복할 수 있도록
    showPred(i)

